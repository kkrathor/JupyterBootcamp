{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Apache Spark™ is a unified analytics engine for large-scale data processing. Spark provides an interface for programming entire clusters with implicit data parallelism and fault tolerance. On Single Machine , Spark can have lower memory consumption and can process more data than laptop ’s memory size, as it does not require loading the entire data set into memory before processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intialize context to interact with Spark Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "...     .master(\"local\") \\\n",
    "...     .appName(\"Word Count\") \\\n",
    "...     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Builder',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_convert_from_pandas',\n",
       " '_createFromLocal',\n",
       " '_createFromRDD',\n",
       " '_create_from_pandas_with_arrow',\n",
       " '_create_shell_session',\n",
       " '_get_numpy_record_dtype',\n",
       " '_inferSchema',\n",
       " '_inferSchemaFromList',\n",
       " '_instantiatedSession',\n",
       " '_jsc',\n",
       " '_jsparkSession',\n",
       " '_jvm',\n",
       " '_jwrapped',\n",
       " '_repr_html_',\n",
       " '_sc',\n",
       " '_wrapped',\n",
       " 'builder',\n",
       " 'catalog',\n",
       " 'conf',\n",
       " 'createDataFrame',\n",
       " 'newSession',\n",
       " 'range',\n",
       " 'read',\n",
       " 'readStream',\n",
       " 'sparkContext',\n",
       " 'sql',\n",
       " 'stop',\n",
       " 'streams',\n",
       " 'table',\n",
       " 'udf',\n",
       " 'version']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.3'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Log file and Perform Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = r'D:\\jupyter bootcamp\\clonedrepo\\notebooks\\testdata\\apache_logs\\apache.access.log.PROJECT_2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = spark.read.text(log_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|value                                                                                                                              |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "|reports.arc.nasa.gov - - [09/Aug/1995:13:23:23 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1713                              |\n",
      "|atl57298.bwi.wec.com - - [09/Aug/1995:13:23:24 -0400] \"GET /shuttle/missions/sts-71/movies/sts-71-launch-3.mpg HTTP/1.0\" 200 130724|\n",
      "|cat.dbs.ucdavis.edu - - [09/Aug/1995:13:23:24 -0400] \"GET /shuttle/missions/sts-70/mission-sts-70.html HTTP/1.0\" 200 20113         |\n",
      "|gorgax06.pixi.com - - [09/Aug/1995:13:23:24 -0400] \"GET /images/USA-logosmall.gif HTTP/1.0\" 200 234                                |\n",
      "|russell.dp.ox.ac.uk - - [09/Aug/1995:13:23:24 -0400] \"GET /history/apollo/apollo-13/apollo-13.html HTTP/1.0\" 200 18556             |\n",
      "|cat.dbs.ucdavis.edu - - [09/Aug/1995:13:23:24 -0400] \"GET /shuttle/missions/sts-70/sts-70-patch-small.gif HTTP/1.0\" 200 5978       |\n",
      "|disarray.demon.co.uk - - [09/Aug/1995:13:23:25 -0400] \"GET / HTTP/1.0\" 200 7131                                                    |\n",
      "|russell.dp.ox.ac.uk - - [09/Aug/1995:13:23:25 -0400] \"GET /history/apollo/apollo-13/apollo-13-patch-small.gif HTTP/1.0\" 200 12859  |\n",
      "|gorgax06.pixi.com - - [09/Aug/1995:13:23:26 -0400] \"GET /images/WORLD-logosmall.gif HTTP/1.0\" 200 669                              |\n",
      "|russell.dp.ox.ac.uk - - [09/Aug/1995:13:23:27 -0400] \"GET /history/apollo/images/footprint-logo.gif HTTP/1.0\" 200 4209             |\n",
      "|168.166.39.49 - - [09/Aug/1995:13:23:28 -0400] \"GET /images/NASA-logosmall.gif HTTP/1.0\" 200 786                                   |\n",
      "|168.166.39.49 - - [09/Aug/1995:13:23:28 -0400] \"GET /images/MOSAIC-logosmall.gif HTTP/1.0\" 200 363                                 |\n",
      "|russell.dp.ox.ac.uk - - [09/Aug/1995:13:23:30 -0400] \"GET /images/ksclogosmall.gif HTTP/1.0\" 200 3635                              |\n",
      "|cat.dbs.ucdavis.edu - - [09/Aug/1995:13:23:32 -0400] \"GET /images/launch-logo.gif HTTP/1.0\" 200 1713                               |\n",
      "|cat.dbs.ucdavis.edu - - [09/Aug/1995:13:23:32 -0400] \"GET /history/apollo/images/apollo-logo1.gif HTTP/1.0\" 200 1173               |\n",
      "|168.166.39.49 - - [09/Aug/1995:13:23:34 -0400] \"GET /images/USA-logosmall.gif HTTP/1.0\" 200 234                                    |\n",
      "|168.166.39.49 - - [09/Aug/1995:13:23:35 -0400] \"GET /images/WORLD-logosmall.gif HTTP/1.0\" 200 669                                  |\n",
      "|benz.ece.cmu.edu - - [09/Aug/1995:13:23:36 -0400] \"GET /shuttle/missions/sts-70/o-ring-problem.gif HTTP/1.0\" 200 16197             |\n",
      "|n239-si-24.arc.nasa.gov - - [09/Aug/1995:13:23:43 -0400] \"GET /shuttle/technology/sts-newsref/sts_eclss.html HTTP/1.0\" 200 38675   |\n",
      "|129.79.25.97 - - [09/Aug/1995:13:23:53 -0400] \"GET /shuttle/missions/sts-73/mission-sts-73.html HTTP/1.0\" 200 4102                 |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, value: string]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350296"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+--------------------------+---------------------------------------------------+------+------------+\n",
      "|host                    |timestamp                 |path                                               |status|content_size|\n",
      "+------------------------+--------------------------+---------------------------------------------------+------+------------+\n",
      "|reports.arc.nasa.gov    |09/Aug/1995:13:23:23 -0400|/images/launch-logo.gif                            |200   |1713        |\n",
      "|atl57298.bwi.wec.com    |09/Aug/1995:13:23:24 -0400|/shuttle/missions/sts-71/movies/sts-71-launch-3.mpg|200   |130724      |\n",
      "|cat.dbs.ucdavis.edu     |09/Aug/1995:13:23:24 -0400|/shuttle/missions/sts-70/mission-sts-70.html       |200   |20113       |\n",
      "|gorgax06.pixi.com       |09/Aug/1995:13:23:24 -0400|/images/USA-logosmall.gif                          |200   |234         |\n",
      "|russell.dp.ox.ac.uk     |09/Aug/1995:13:23:24 -0400|/history/apollo/apollo-13/apollo-13.html           |200   |18556       |\n",
      "|cat.dbs.ucdavis.edu     |09/Aug/1995:13:23:24 -0400|/shuttle/missions/sts-70/sts-70-patch-small.gif    |200   |5978        |\n",
      "|disarray.demon.co.uk    |09/Aug/1995:13:23:25 -0400|/                                                  |200   |7131        |\n",
      "|russell.dp.ox.ac.uk     |09/Aug/1995:13:23:25 -0400|/history/apollo/apollo-13/apollo-13-patch-small.gif|200   |12859       |\n",
      "|gorgax06.pixi.com       |09/Aug/1995:13:23:26 -0400|/images/WORLD-logosmall.gif                        |200   |669         |\n",
      "|russell.dp.ox.ac.uk     |09/Aug/1995:13:23:27 -0400|/history/apollo/images/footprint-logo.gif          |200   |4209        |\n",
      "|168.166.39.49           |09/Aug/1995:13:23:28 -0400|/images/NASA-logosmall.gif                         |200   |786         |\n",
      "|168.166.39.49           |09/Aug/1995:13:23:28 -0400|/images/MOSAIC-logosmall.gif                       |200   |363         |\n",
      "|russell.dp.ox.ac.uk     |09/Aug/1995:13:23:30 -0400|/images/ksclogosmall.gif                           |200   |3635        |\n",
      "|cat.dbs.ucdavis.edu     |09/Aug/1995:13:23:32 -0400|/images/launch-logo.gif                            |200   |1713        |\n",
      "|cat.dbs.ucdavis.edu     |09/Aug/1995:13:23:32 -0400|/history/apollo/images/apollo-logo1.gif            |200   |1173        |\n",
      "|168.166.39.49           |09/Aug/1995:13:23:34 -0400|/images/USA-logosmall.gif                          |200   |234         |\n",
      "|168.166.39.49           |09/Aug/1995:13:23:35 -0400|/images/WORLD-logosmall.gif                        |200   |669         |\n",
      "|benz.ece.cmu.edu        |09/Aug/1995:13:23:36 -0400|/shuttle/missions/sts-70/o-ring-problem.gif        |200   |16197       |\n",
      "|n239-si-24.arc.nasa.gov |09/Aug/1995:13:23:43 -0400|/shuttle/technology/sts-newsref/sts_eclss.html     |200   |38675       |\n",
      "|129.79.25.97            |09/Aug/1995:13:23:53 -0400|/shuttle/missions/sts-73/mission-sts-73.html       |200   |4102        |\n",
      "+------------------------+--------------------------+---------------------------------------------------+------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, regexp_extract\n",
    "split_df = base_df.select(regexp_extract('value', r'^([^\\s]+\\s)', 1).alias('host'),\n",
    "                          regexp_extract('value', r'^.*\\[(\\d\\d/\\w{3}/\\d{4}:\\d{2}:\\d{2}:\\d{2} -\\d{4})]', 1).alias('timestamp'),\n",
    "                          regexp_extract('value', r'^.*\"\\w+\\s+([^\\s]+)\\s+HTTP.*\"', 1).alias('path'),\n",
    "                          regexp_extract('value', r'^.*\"\\s+([^\\s]+)', 1).cast('integer').alias('status'),\n",
    "                          regexp_extract('value', r'^.*\\s+(\\d+)$', 1).cast('integer').alias('content_size'))\n",
    "split_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+----+------+------------+\n",
      "|host|timestamp|path|status|content_size|\n",
      "+----+---------+----+------+------------+\n",
      "|   0|        0|   0|     0|        2677|\n",
      "+----+---------+----+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check  if new df has any null values\n",
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "def count_null(col_name):\n",
    "  return sum(col(col_name).isNull().cast('integer')).alias(col_name)\n",
    "\n",
    "# Build up a list of column expressions, one per column.\n",
    "#\n",
    "# This could be done in one line with a Python list comprehension, but we're keeping\n",
    "# it simple for those who don't know Python very well.\n",
    "exprs = []\n",
    "for col_name in split_df.columns:\n",
    "  exprs.append(count_null(col_name))\n",
    "\n",
    "# Run the aggregation. The *exprs converts the list of expressions into\n",
    "# variable function arguments.\n",
    "split_df.agg(*exprs).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill all null values with 0\n",
    "cleaned_df = split_df.na.fill({'content_size': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+----+------+------------+\n",
      "|host|timestamp|path|status|content_size|\n",
      "+----+---------+----+------+------------+\n",
      "|   0|        0|   0|     0|           0|\n",
      "+----+---------+----+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure that there are no nulls left.\n",
    "exprs = []\n",
    "for col_name in cleaned_df.columns:\n",
    "      exprs.append(count_null(col_name))\n",
    "\n",
    "cleaned_df.agg(*exprs).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handle Timestamp in dataframe\n",
    "from datetime import datetime as dt\n",
    "converted= dt.strptime(\"09/Aug/1995:13:23:23 -0400\", \"%d/%b/%Y:%H:%M:%S %z\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1995, 8, 9, 13, 23, 23, tzinfo=datetime.timezone(datetime.timedelta(days=-1, seconds=72000)))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from datetime import datetime as dt\n",
    "\n",
    "def parse_clf_time(s):\n",
    "    return dt.strptime(s, \"%d/%b/%Y:%H:%M:%S %z\")\n",
    "\n",
    "u_parse_time = udf(parse_clf_time)\n",
    "\n",
    "logs_df = cleaned_df.select('*', u_parse_time(split_df['timestamp']).cast('timestamp').alias('time')).drop('timestamp')\n",
    "total_log_entries = logs_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "month_map = {\n",
    "  'Jan': 1, 'Feb': 2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7,\n",
    "  'Aug':8,  'Sep': 9, 'Oct':10, 'Nov': 11, 'Dec': 12\n",
    "}\n",
    "\n",
    "def parse_clf_time(s):\n",
    "    \"\"\" Convert Common Log time format into a Python datetime object\n",
    "    Args:\n",
    "        s (str): date and time in Apache time format [dd/mmm/yyyy:hh:mm:ss (+/-)zzzz]\n",
    "    Returns:\n",
    "        a string suitable for passing to CAST('timestamp')\n",
    "    \"\"\"\n",
    "    # NOTE: We're ignoring time zone here. In a production application, you'd want to handle that.\n",
    "    return \"{0:04d}-{1:02d}-{2:02d} {3:02d}:{4:02d}:{5:02d}\".format(\n",
    "      int(s[7:11]),\n",
    "      month_map[s[3:6]],\n",
    "      int(s[0:2]),\n",
    "      int(s[12:14]),\n",
    "      int(s[15:17]),\n",
    "      int(s[18:20])\n",
    "    )\n",
    "\n",
    "u_parse_time = udf(parse_clf_time)\n",
    "\n",
    "logs_df = cleaned_df.select('*', u_parse_time(split_df['timestamp']).cast('timestamp').alias('time')).drop('timestamp')\n",
    "total_log_entries = logs_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- host: string (nullable = true)\n",
      " |-- path: string (nullable = true)\n",
      " |-- status: integer (nullable = true)\n",
      " |-- content_size: integer (nullable = false)\n",
      " |-- time: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350296"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_log_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[host: string, path: string, status: int, content_size: int, time: timestamp]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### keep the dataframe in cache for increasing speed\n",
    "logs_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|     content_size|\n",
      "+-------+-----------------+\n",
      "|  count|           350296|\n",
      "|   mean|17778.18860620732|\n",
      "| stddev| 70095.7214882202|\n",
      "|    min|                0|\n",
      "|    max|          3155499|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate statistics based on the content size.\n",
    "content_size_summary_df = logs_df.describe(['content_size'])\n",
    "content_size_summary_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_to_count_df =(logs_df\n",
    "                     .groupBy('status')\n",
    "                     .count()\n",
    "                     .sort('status')\n",
    "                     .cache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 response codes\n",
      "+------+------+\n",
      "|status| count|\n",
      "+------+------+\n",
      "|   200|315078|\n",
      "|   302|  5759|\n",
      "|   304| 27650|\n",
      "|   403|    23|\n",
      "|   404|  1781|\n",
      "|   501|     5|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status_to_count_length = status_to_count_df.count()\n",
    "print('Found %d response codes' % status_to_count_length)\n",
    "status_to_count_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[status: int, count: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(status_to_count_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
